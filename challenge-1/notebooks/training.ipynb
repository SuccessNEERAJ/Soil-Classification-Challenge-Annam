{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG2h-3cWah1W"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "Author: Neeraj Jaiswal\n",
        "Team Name: The Revengers\n",
        "Team Members: Neeraj Jaiswal, Karanbir Singh, Komal Dadwal, Jatin Mahey, Sonu Choubey\n",
        "Leaderboard Rank: 27\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# This is the notebook used for training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import os\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"../data/soil_attributes_output.csv\")\n",
        "\n",
        "# Parse RGB values from 'color' string\n",
        "def parse_rgb(color_str):\n",
        "    nums = color_str.strip(\"rgb()\").split(\",\")\n",
        "    return [int(x.strip()) for x in nums]\n",
        "\n",
        "df[['R', 'G', 'B']] = df['color'].apply(lambda x: pd.Series(parse_rgb(x)))\n",
        "\n",
        "# Features and target\n",
        "feature_cols = ['R', 'G', 'B', 'texture']\n",
        "target_col = 'soil_type'\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[target_col]\n",
        "\n",
        "# Define preprocessing for categorical features\n",
        "categorical_features = ['texture']\n",
        "numeric_features = ['R', 'G', 'B']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'  # Keep numeric features as is\n",
        ")\n",
        "\n",
        "# Build the pipeline\n",
        "clf_pipeline = Pipeline(steps=[\n",
        "    ('preprocess', preprocessor),\n",
        "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Split dataset: 70% train, 15% val, 15% test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "clf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_val_pred = clf_pipeline.predict(X_val)\n",
        "print(\"ðŸ“Š Validation Classification Report:\\n\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# Optional: Final test evaluation\n",
        "y_test_pred = clf_pipeline.predict(X_test)\n",
        "print(\"\\nðŸ“Š Test Set Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Train classes:\\n\", y_train.value_counts())\n",
        "print(\"Val classes:\\n\", y_val.value_counts())\n",
        "print(\"Test classes:\\n\", y_test.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Validation predictions shape:\", y_val_pred.shape)\n",
        "print(\"Test predictions shape:\", y_test_pred.shape)\n",
        "\n",
        "# For example, print first 5 predictions\n",
        "print(\"Validation first 5 preds:\", y_val_pred[:5])\n",
        "print(\"Test first 5 preds:\", y_test_pred[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "labels = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red Soil']\n",
        "\n",
        "# Validation set confusion matrix\n",
        "cm_val = confusion_matrix(y_val, y_val_pred, labels=labels)\n",
        "disp_val = ConfusionMatrixDisplay(confusion_matrix=cm_val, display_labels=labels)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp_val.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Validation Set Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Test set confusion matrix\n",
        "cm_test = confusion_matrix(y_test, y_test_pred, labels=labels)\n",
        "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=labels)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp_test.plot(cmap=plt.cm.Greens)\n",
        "plt.title(\"Test Set Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained pipeline\n",
        "joblib.dump(clf_pipeline, \"../data/soil_classifier_pipeline.joblib\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
